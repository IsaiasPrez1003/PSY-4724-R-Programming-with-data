---
title: 'Lab 8: Text Analysis'
author: "Isaias Perez"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
#install.packages("tidyverse")
#install.packages("flextable")
#install.packages("wordcloud")
#install.packages("stopwords")
#install.packages("schrute")
#install.packages("psych")
#install.packages("dplyr")
#install.packages("ploty")
```

```{r library, include = FALSE}
library(tidyverse)
library(flextable)
library(wordcloud)
library(stopwords)
library(schrute)
library(psych)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(ggsci)
library(plotly)


options(scipen = 999) #removes scientific notation.
```

```{r loading datasets}

#generates and adds the dataset 'episode_ratings' to the environment.
episode_ratings <-readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv') 

#Generates and adds the dataset 'episode_dialogue' to the evironment.
episode_dialogue <- schrute::theoffice

```

***1.** Before we begin to answer the question of “When was The Office at its best”, I want to practice using stringr. To begin, open up the stringr cheatsheet (<https://github.com/rstudio/cheatsheets/blob/main/strings.pdf>)*

***a.** For question 1, use the episode_ratings dataset and change the cells within the title column to be all uppercase letters. Use the head function to only report back the first 10 rows.*

```{r question 1}
#This piece of code adjusts all the title's to be capitalized.
episode_ratings <- episode_ratings %>%
  mutate(title = str_to_upper(episode_ratings$title))


head(episode_ratings, n = 10)
```

***2.** Another function within stringr counts the number of characters within a given string.*

***a.** For question 2, use the function that counts the number of characters in combination with mutate to add a new column called “title_character_count” to your “episode_ratings” dataset that reports the number of characters in each title. Use the head function to only report back the first 10 rows.*

```{r question 2}
#This section is creates a new column and displays the total number of characters in each title.
episode_ratings <- episode_ratings %>%
  mutate(title_character_count = str_count(episode_ratings$title))

head(episode_ratings, n = 10)

```

***3.** Now that we’ve dipped our toes into the stringr water, I want to move on to our goal of determining “when” The Office was at its best. For this question, continue using the episode_ratings dataset. For question 3,*

***i.** group the ratings by season and create a table that summarizes the mean imdb_ratings (imdb_ratings hereby called ratings) for each season.*

***ii.** Then create a table that you would be willing to present to a business audience (i.e., use flextable and make it neat) and tell me which season of The Office had the highest ratings and which had the lowest ratings.*

```{r question 3}
#This line of code creates a new dataset named "episode_ratings_imdb_ratings" and groups each season together and creates a mean score for imdb_ratings.
episode_ratings_imdb_ratings <- episode_ratings %>% 
  group_by(season) %>%
  summarise(mean = mean(imdb_rating), n = n ()) 
#This line is responsible for renaming the columns.
episode_ratings_imdb_ratings <- rename(episode_ratings_imdb_ratings, "Season of the Office" = season, "Mean rating of season" = mean, "Number of episodes" = n)
#This line generates a flextable 
imdb_rating_flextable <- flextable(episode_ratings_imdb_ratings, cwidth = 1)

imdb_rating_flextable

#season 4 had the highest rating
```

***4.** Next, I want to dive into the episode_dialogue dataset. Specifically, I want to know who had the most dialogue within the highest rated season. For question 4,*

***i.** Filter the dataset to only the highest rated season* ***ii.** Then group the data by character* ***iii.** Then report the count of the number of times each character spoke* ***iv.** After executing this code tell me how many times Angela speaks in this season.*

```{r question 4}

# This line filters all seasons out except for season 4 and groups characters together by using the arrange function
episode_dialogue <- episode_dialogue %>% arrange(character) %>%
  filter(season == 4) 

episode_dialogue

#This line produces a small table showing the frequency of times a character spoke.
ep_chr_count <- episode_dialogue %>% count(character)

ep_chr_count

#Angela spoke a total of 171 times
```

###5.## The dataset outputted in question 4 is far too big. One thing I’ve noticed is our dataset includes times where multiple characters spoke at the same time. In my analysis, I want to focus on which characters get the most standalone speaking time. For question 5,#

###i.## Identify what common traits are present when there is more than one speaker#

###ii.## Then use the filter and str_detect functions in combination to remove any rows that provide the count for more than one speaker.#

```{r question 5}
#Common traits which are consistent across variables is the occurrence of commas and the word 'and'


#These lines and responsible for detecting certain words and removing them. Words in parathesis are removed.
episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "All"))

episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "and"))

episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "Both"))

episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "Everybody"))

episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "Everyone"))

episode_dialogue <- episode_dialogue %>% filter(!str_detect(character, "[:punct:]"))


as_tibble(episode_dialogue)

```

***6.** In looking at the dataset, there are a few typos present that lessen the quality of our data. We always want to ensure that our data is perfect, so we’re going to go in and fix those.*

***a.** Within the originally downloaded episodes_dialogue dataset, use str_replace to fix the following errors in the character column by changing the incorrect name to the correct name:*

***i.** There is one instance of “Angels,” which seems to be a typo for Angela*

***ii.** There are three instances of “DwightKSchrute,” which is a typo for Dwight*

***iii.** There is one instance of a “Holy,” which seems to be a typo for Holly*

***iv.** There is one instance of “Jan [on phone]” which should be lumped in with the other Jan rows*

\*\*\*v. There is one instance of a “Micael,” “Michae ,” and “Micahel”, which all seem to be typos for Michael

***vi.** There is one instance of a “sAndy,” which seems to be a typo for Andy*

***b.** For question 6, use your updated dataset and re-run your code from question 4 to create a table (does not have to be business-audience ready as we’ll do that next question) reflecting the number of times that someone speaks. Report one example of how you know your str_replace_all code worked.*

```{r question 6}

#This section is responsible for changing certain words and replacing them with another.
episode_dialogue$character <- str_replace(episode_dialogue$character, "Angels", "Angela")

episode_dialogue$character <- str_replace(episode_dialogue$character, "DwightKSchrute", "Dwight")

episode_dialogue$character <- str_replace(episode_dialogue$character, "Holy", "Holly")

episode_dialogue$character <- str_replace(episode_dialogue$character, "Jan [on phone]", "Jan")

episode_dialogue$character <- str_replace(episode_dialogue$character, "Micael", "Michael")

episode_dialogue$character <- str_replace(episode_dialogue$character, "Michae ", "Michael")

episode_dialogue$character <- str_replace(episode_dialogue$character, "Micahel", "Michael")

episode_dialogue$character <- str_replace(episode_dialogue$character, "sAndy", "Andy")

#This line creates a new table that displays characters and the frequency at which they speak.
episode_dialogue_count <- episode_dialogue %>% count(character)

episode_dialogue_count

```

***7.** Next, I’d like to visualize this data. Before doing so, add another filter to your table so that only those with 100 or more incidents of standalone dialogue are shown as I only want to examine core members from this season of The Office.*

***a.** For question 7, create a table and/or plot that you would be willing to present to a business audience (i.e., format the figure you’re creating) reflecting the amount of standalone lines each character had and tell me which three characters had the most lines of standalone dialogue.*

```{r question 7}

episode_dialogue_count <- episode_dialogue_count %>% filter(n >= 100)

#construction of graph
Q7_plot <- ggplot(data = episode_dialogue_count, aes(x = character, y = n, fill = character)) +
  geom_col() +
  theme_bw() +
  scale_y_continuous(breaks = c(0, 500, 1000, 1500)) +
  labs(x = "Characters", y = "Dialogue frequency") +
  geom_text(aes(label = n), vjust = -0.5, size = 3)

Q7_plot

#Michael, Jim, and Dwight has the most lines
```

***8.** Thus far we’ve examined which season was most popular and who spoke the most within the most popular season. Another aspect of The Office that may be relevant to when The Office was at its best was who the writer was. Specifically, in using the function “unique(episode_dialogue\$writer),” I can see that there were many writers and that some episodes had one writer while others had two or more.*

***i.** Note: You may want to use the mutate, str_detect, and if_else functions to accomplish this by creating a new column called multi_writer_yn (or something to that effect) and using this as your x variable*

```{r question 8}
unique(episode_dialogue$writer) #Shows the different names within the writer column.

episode_dialogue <- episode_dialogue %>%
  mutate(multi_writer_yn = if_else(str_detect(writer, ";"), "Yes", "No")) # Generates another column which either displays a yes for multiple writers, or no for only 1 writer.

episode_dialogue


Q8_plot <- ggplot(data = episode_dialogue, aes(x = multi_writer_yn, y = imdb_rating, fill = multi_writer_yn)) +
  geom_boxplot() +
  theme_bw() + 
  scale_y_continuous(trans = "log10")


Q8_plot

#episodes with multiple writers typically have higher ratings.

```

***9.** At this point, I feel as though we have a solid grasp on when The Office was at its best. As additional stringr practice before we wrap this lab up, filter your episode_dialogue dataset so that it only consists of episodes that were written by one person and save this new dataset as “one_writer_data.”*

***a. ** For question 9*

\***i.** Reduce this dataset such that you only select to retain the episode title, the writer, and the director columns\*\*

***ii.** Create a new column called sentence that pastes together the episode title, the writer, and the director columns in the following format: This episode was written by -writer name- and directed by -director name- and is titled -episode name-*

***iii.** Call the head function such that I only see the output for the first 10 rows of data*

```{r question 9}
# This line is responsible for creating a new data set and filtering out the writer column with the occurrence of ";". 
one_writer_data <- episode_dialogue %>%
  filter(!str_detect(writer, ";"))  

#Creates a new column called sentence that pastes together the episode title, the writer, and the director columns
one_writer_data <- episode_dialogue %>%
  select(episode_name, writer, director) %>%
  mutate(sentence = paste("This episode was written by", writer, "and directed by", director, "and is titled", episode_name))


one_writer_data <- one_writer_data %>% distinct()

head(one_writer_data, 10)

```

```{r question 10}
data <- episode_dialogue %>% filter(character == "Michael") #filters data for only Michael
data <- as.vector(data$text) #sets text to be a vector
data <- str_flatten(data) #puts all text together
data <- str_split(data, pattern = " ") #sets each word separate (done using “ “ as the separator
data <- unlist(data[1]) #takes our data out of list form
data <- str_to_lower(data) #sets all capitalization to be standard
data <- data.frame(Word = data) #creates dataframe with the column Word
data <- data %>% group_by(Word) %>% count() #adds count of words
stop <- data.frame(Word = stopwords::stopwords()) #creates dataframe of stopwords
data <- anti_join(data, stop, by = "Word") #removes all stopwords from our dataset
data %>% arrange(desc(n)) #arranges data in order from most to least by count

wordcloud(words = data$Word, freq = data$n, min.freq = 5, 
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2")) #creates wordcloud
```

```{r question 10 Michael}

#Word cloud for Jim
data <- episode_dialogue %>% filter(character == "Jim") 
data <- as.vector(data$text) 
data <- str_flatten(data) 
data <- str_split(data, pattern = " ") 
data <- unlist(data[1]) 
data <- str_to_lower(data) 
data <- data.frame(Word = data) 
data <- data %>% group_by(Word) %>% count() 
stop <- data.frame(Word = stopwords::stopwords()) 
data <- anti_join(data, stop, by = "Word") 
data %>% arrange(desc(n)) 

wordcloud(words = data$Word, freq = data$n, min.freq = 5, 
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2")) 
```


```{r question 10 Dwight}
#Word cloud for Dwight
data <- episode_dialogue %>% filter(character == "Dwight") 
data <- as.vector(data$text) 
data <- str_flatten(data) 
data <- str_split(data, pattern = " ") 
data <- unlist(data[1]) 
data <- str_to_lower(data) 
data <- data.frame(Word = data) 
data <- data %>% group_by(Word) %>% count() 
stop <- data.frame(Word = stopwords::stopwords()) 
data <- anti_join(data, stop, by = "Word") 
data %>% arrange(desc(n)) 

wordcloud(words = data$Word, freq = data$n, min.freq = 5, 
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2")) 
```

```{r question 10 Pam}
#Word cloud for Pam
data <- episode_dialogue %>% filter(character == "Pam") 
data <- as.vector(data$text) 
data <- str_flatten(data) 
data <- str_split(data, pattern = " ") 
data <- unlist(data[1]) 
data <- str_to_lower(data) 
data <- data.frame(Word = data) 
data <- data %>% group_by(Word) %>% count() 
stop <- data.frame(Word = stopwords::stopwords()) 
data <- anti_join(data, stop, by = "Word") 
data %>% arrange(desc(n)) 

wordcloud(words = data$Word, freq = data$n, min.freq = 5, 
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2")) 

```

***Across the four wordclouds, words such as "just", "know", and "can" showed up fairly frequently. This was decided by viewing the accompanying tibble with the word cloud.*


